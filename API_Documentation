# Data Pipeline API Documentation

## Overview

This API provides access to processed TechCorner mobile sales data with support for date-based filtering, demographic filtering, and cursor-based pagination. The data is sourced from the [TechCorner Mobile Purchase and Engagement Data](https://www.kaggle.com/datasets/shohinurpervezshohan/techcorner-mobile-purchase-and-engagement-data) dataset on Kaggle, which has been processed through our data pipeline.

The API is secured with API key authentication and implements rate limiting to ensure fair usage.

## Authentication

All API requests require an API key to be included in the `X-API-Key` header:

```
X-API-Key: your_api_key_here
```

To obtain an API key, please contact the administrator.

## Rate Limiting

The API implements rate limiting of 100 requests per minute per API key. If you exceed this limit, you will receive a `429 Too Many Requests` response. Please adjust your request rate accordingly.

## Endpoints

### GET /data

Retrieve processed data with date filtering and cursor-based pagination.

#### Query Parameters

| Parameter  | Type   | Required | Description |
|------------|--------|----------|-------------|
| start_date | Date   | No       | Filter data from this date (format: YYYY-MM-DD) |
| end_date   | Date   | No       | Filter data until this date (format: YYYY-MM-DD) |
| location   | String | No       | Filter by customer location |
| gender     | String | No       | Filter by gender (Male/Female) |
| min_age    | Integer| No       | Filter by minimum age |
| max_age    | Integer| No       | Filter by maximum age |
| mobile_name| String | No       | Filter by mobile device name |
| cursor     | String | No       | Pagination cursor for retrieving the next set of results |
| limit      | Integer| No       | Number of records to return (default: 50, max: 100) |

#### Response

```json
{
  "items": [
    {
      "id": 1,
      "customer_id": 10245,
      "date": "2022-01-15T00:00:00",
      "customer_location": "New York",
      "age": 28,
      "gender": "Male",
      "mobile_name": "iPhone 13 Pro",
      "sell_price": 999.99,
      "from_facebook": "Yes",
      "followed_page": "Yes",
      "previous_purchase": "No",
      "heard_of_shop": "Yes",
      "source_file": "TechCorner_Sales_update.csv",
      "processed_at": "2023-01-15T12:30:45"
    },
    // More items...
  ],
  "next_cursor": "1001",  // ID to use as cursor for the next page, null if no more results
  "total_count": 8871     // Total number of records matching the query
}
```

#### Example Requests

**Basic request:**
```
GET /data HTTP/1.1
Host: api.example.com
X-API-Key: your_api_key_here
```

**With date filtering:**
```
GET /data?start_date=2023-01-01&end_date=2023-01-31 HTTP/1.1
Host: api.example.com
X-API-Key: your_api_key_here
```

**With pagination:**
```
GET /data?limit=10&cursor=1001 HTTP/1.1
Host: api.example.com
X-API-Key: your_api_key_here
```

### GET /health

Health check endpoint for monitoring the API status.

#### Response

```json
{
  "status": "healthy",
  "timestamp": "2023-01-01T12:00:00"
}
```

## Error Handling

The API uses standard HTTP status codes to indicate the success or failure of a request:

| Status Code | Description |
|-------------|-------------|
| 200         | Success     |
| 400         | Bad Request - Invalid parameters |
| 401         | Unauthorized - Invalid or missing API key |
| 404         | Not Found - Resource not found |
| 429         | Too Many Requests - Rate limit exceeded |
| 500         | Internal Server Error - Something went wrong on the server |

Error responses include a JSON body with more details:

```json
{
  "detail": "Error message describing the issue"
}
```

## Pagination

The API uses cursor-based pagination for efficient retrieval of large datasets:

1. Make an initial request without a cursor
2. In the response, look for the `next_cursor` field
3. If `next_cursor` is not null, use its value in the `cursor` parameter of your next request
4. Repeat until `next_cursor` is null, indicating no more results

This approach is more efficient than offset-based pagination for large datasets and ensures consistency when data is being added concurrently.